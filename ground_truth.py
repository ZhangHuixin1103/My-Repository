# -*- coding: utf-8 -*-
"""ground_truth.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TqtEIX1txNxM6Q_URjb6x884fjkUQDTm

## generate graph data

node number 10 and edge probability 0.5

node feature: constant

label: zero-centered
"""

import matplotlib.pyplot as plt
import networkx as nx
import numpy as np
from scipy.sparse.linalg import eigsh
from torch_geometric.utils import from_networkx, tree_decomposition, to_networkx
from torch_geometric.utils import add_self_loops, degree
import torch
import os
import pickle
import pandas as pd

def G_Heisenberg(G): 
    """
    one of the simplest quantum many-body model
    H = \sum sigma^z_i*sigma^z_j + sigma^x_i*sigma^x_j + sigma^y_i*sigma^y_j
      = sigma^z_i*sigma^z_j + 2s^+_i*s^-_j + 2s^-_i*s^+_j
    """
    num_node = G.number_of_nodes()
    H=np.zeros((2**num_node,2**num_node),dtype=float)
    for state in range(0,2**num_node): # loop over all states
        config = np.binary_repr(state,num_node)[::-1]
        for edge in G.edges:
            bit0 = int(config[edge[0]]) #the state of first qbit
            bit1 = int(config[edge[1]]) #the state of the second qubit
            H[state,state] = H[state,state] + (2*bit0-1)*(2*bit1-1) #the diagonal part of the Hamiltonian
            tmp_state = state - (bit0-bit1)*2**edge[0] - (bit1-bit0)*2**edge[1]
            if tmp_state!=state:
                H[tmp_state,state]+=2 #the off diagonal part of the Hamiltonian
    return H

G_list = []
energy_array = []
for i in range(20):
    G = nx.generators.erdos_renyi_graph(10,0.5)
    node_feat = np.eye(10)
    for n in range(10):
#                 print(n)
        G.nodes[n]['x'] = np.array([1.])
#                 G.nodes[n]['x'] = np.ones(10)
    G_list.append(G)
    H = G_Heisenberg(G)
    [energy,state]=eigsh(H,k=1,which='SA')
    energy_array = np.hstack((energy_array,energy))

print(energy_array[0])

energy_array = energy_array - np.mean(energy_array)
v_max = np.max(energy_array)
v_min = np.min(energy_array)
print(v_min)
print(v_max)
bins = np.linspace(v_min,v_max,20,endpoint=True)
# print(bins)
plt.hist(energy_array,bins=bins)
plt.show()

dataset = []
for idx, nx in enumerate(G_list):
    data = from_networkx(nx)

    ### data format
    # x: torch.float32
    # edge_index: torch.int64
    # edge_attr: torch.float32
    # y: torch.float32
    # graph_attr: torch.float32
    
    edge_index = data.edge_index
    row, col = edge_index
    deg = degree(col, data['x'].size(0), dtype=data['x'].dtype)
    data['x'] = deg.view(data['x'].size(0),-1)
    
    data['x'] = torch.tensor(data['x'], dtype=torch.float32)
    data['edge_index'] = torch.tensor(data['edge_index'], dtype=torch.int64)
    data['y'] = torch.tensor(energy_array[idx], dtype=torch.float32)

    dataset.append(data)

torch.save(dataset, './data/10_node.pt')

"""node feature: constant

label: divide by edge number


G_list = []
energy_array = []
prob = np.arange(0.2,1,0.1)
node = range(3,11,1)
for i in range(15):
    for j in range(len(prob)):
        for k in range(len(node)):
            G = nx.generators.erdos_renyi_graph(node[k],prob[j])
            node_feat = np.eye(15)
            for n in range(node[k]):
#                 print(n)
                G.nodes[n]['x'] = np.array([1.])
#                 G.nodes[n]['x'] = np.ones(10)
            G_list.append(G)
            H = G_Heisenberg(G)
            [energy,state]=eigsh(H,k=1,which='SA')
            energy_array = np.hstack((energy_array,energy))
v_max = np.max(energy_array)
v_min = np.min(energy_array)
print(v_min)
print(v_max)
bins = np.linspace(v_min,v_max,20,endpoint=True)
# print(bins)
plt.hist(energy_array,bins=bins)
plt.show()

dataset = []
for idx, nx in enumerate(G_list):
    data = from_networkx(nx)

    ### data format
    # x: torch.float32
    # edge_index: torch.int64
    # edge_attr: torch.float32
    # y: torch.float32
    # graph_attr: torch.float32
    data['x'] = torch.tensor(data['x'], dtype=torch.float32)
    data['edge_index'] = torch.tensor(data['edge_index'], dtype=torch.int64)
    if float(data.num_edges) != 0.0:
        energy_array[idx] = energy_array[idx] / float(data.num_edges)
    data['y'] = torch.tensor(energy_array[idx], dtype=torch.float32)

    dataset.append(data)

torch.save(dataset, '../data/' + 'quantum_divide_edge_num' + '.pt')
"""
"""## get ground truth"""

import numpy as np
import os
import networkx as nx
from tqdm import tqdm
from copy import deepcopy
from scipy.sparse.linalg import eigsh
from torch.utils.tensorboard import SummaryWriter
import matplotlib.pyplot as plt
from numpy.random import randn
import random
import time
import argparse
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.nn import ReLU
from torch_scatter import scatter_sum

from torch_geometric.utils import from_networkx, degree, sort_edge_index
from torch_geometric.nn import GATConv, GraphConv, GCNConv, GINConv, GINEConv, Set2Set, GENConv, DeepGCNLayer
from torch_geometric.nn import global_mean_pool,global_max_pool,global_add_pool, LayerNorm, BatchNorm, GlobalAttention


### Adaptively adjust from https://github.com/GiggleLiu/marburg

num_spin = 10
num_hidden = 10

data = None

def tensor_prod_graph_Heisenberg(data, J=-1, h=-0.5, n=10):

    def tensor_prod(idx, s, size=10, J=-1, h=-0.5):

        Id = np.array([[1,0],[0,1]])
        idx, s = np.array(idx), np.array(s)
        matrices = [Id if k not in idx else s for k in range(size)]
        prod = matrices[0]
        for k in range(1, size):
            prod = np.kron(prod, matrices[k])
        return prod

    sx = np.array([[0,1],[1,0]])
    sz = np.array([[1,0],[0,-1]])
    sy = np.array([[0,-1j],[1j,0]])
    
    idx_list = []
    for i in range(data.edge_index.shape[1]):
        if data.edge_index[0,i] < data.edge_index[1,i]:
            idx_list.append(data.edge_index[:,i].numpy().tolist())
    
    H_1 = sum([tensor_prod(idx, sz, size=n) for idx in idx_list])
    H_2 = sum([tensor_prod(idx, sx, size=n) for idx in idx_list])
    H_3 = sum([tensor_prod(idx, sy, size=n) for idx in idx_list])
    H = (H_1 + H_2 + H_3)
    
    return H


def vmc_sample(kernel, initial_config, num_bath, num_sample):
    '''
    obtain a set of samples.

    Args:
        kernel (object): defines how to sample, requiring the following methods:
            * propose_config, propose a new configuration.
            * prob, get the probability of specific distribution.
        initial_config (1darray): initial configuration.
        num_bath (int): number of updates to thermalize.
        num_sample (int): number of samples.

    Return:
        list: a list of spin configurations.
    '''
    print_step = np.Inf  # steps between two print of accept rate, Inf to disable showing this information.

    config = initial_config
    prob = kernel.prob(config)

    n_accepted = 0
    sample_list = []
    for i in range(num_bath + num_sample):
#         print('sample ', i)
        # generate new config and calculate probability ratio
        config_proposed = kernel.propose_config(config)
        prob_proposed = kernel.prob(config_proposed)

        # accept/reject a move by metropolis algorithm
        if np.random.random() < prob_proposed / prob:
            config = config_proposed
            prob = prob_proposed
            n_accepted += 1

        # print statistics
        if i % print_step == print_step - 1:
            print('%-10s Accept rate: %.3f' %
                  (i + 1, n_accepted * 1. / print_step))
            n_accepted = 0

        # add a sample
        if i >= num_bath:
            sample_list.append(config)
    return sample_list


def vmc_measure(local_measure, sample_list, measure_step, num_bin=50):
    '''
    perform measurements on samples

    Args:
        local_measure (func): local measurements function, input configuration, return local energy and local gradient.
        sample_list (list): a list of spin configurations.
        num_bin (int): number of bins in binning statistics.
        meaure_step: number of samples skiped between two measurements + 1.

    Returns:
        tuple: expectation valued of energy, gradient, energy*gradient and error of energy.
    '''
    # measurements
    energy_loc_list, grad_loc_list = [], []
    for i, config in enumerate(sample_list):
        if i % measure_step == 0:
            # back-propagation is used to get gradients.
            energy_loc, grad_loc = local_measure(config)
            energy_loc_list.append(energy_loc)
            grad_loc_list.append(grad_loc)

    # binning statistics for energy
    energy_loc_list = np.array(energy_loc_list)
    energy, energy_precision = binning_statistics(energy_loc_list, num_bin=num_bin)

    # get expectation values
    energy_loc_list = torch.from_numpy(energy_loc_list)
    if grad_loc_list[0][0].is_cuda: energy_loc_list = energy_loc_list.cuda()
    grad_mean = []
    energy_grad = []
    for grad_loc in zip(*grad_loc_list):
        grad_loc = torch.stack(grad_loc, 0)
        grad_mean.append(grad_loc.mean(0))
        energy_grad.append(
            (energy_loc_list[(slice(None),) + (None,) * (grad_loc.dim() - 1)] * grad_loc).mean(0))
    return energy.item(), grad_mean, energy_grad, energy_precision



def binning_statistics(var_list, num_bin):
    '''
    binning statistics for variable list.
    '''
    num_sample = len(var_list)
    if num_sample % num_bin != 0:
        raise
    size_bin = num_sample // num_bin

    # mean, variance
    mean = np.mean(var_list, axis=0)
    variance = np.var(var_list, axis=0)

    # binned variance and autocorrelation time.
    variance_binned = np.var(
        [np.mean(var_list[size_bin * i:size_bin * (i + 1)]) for i in range(num_bin)])
    t_auto = 0.5 * size_bin * \
        np.abs(np.mean(variance_binned) / np.mean(variance))
    stderr = np.sqrt(variance_binned / num_bin)
    print('Binning Statistics: Energy = %.4f +- %.4f, Auto correlation Time = %.4f' %
          (mean, stderr, t_auto))
    return mean, stderr

class VMCKernel(object):
    '''
    variational monte carlo kernel.

    Attributes:
        energy_loc (func): local energy <x|H|\psi>/<x|\psi>.
        ansatz (Module): torch neural network.
    '''
    def __init__(self, data, energy_loc, ansatz):
        self.ansatz = ansatz
        self.energy_loc = energy_loc
        self.data = data

    def prob(self, config):
        '''
        probability of configuration.

        Args:
            config (1darray): the bit string as a configuration.

        Returns:
            number: probability |<config|psi>|^2.
        '''
        return abs(self.ansatz.psi(self.data, torch.from_numpy(config)).item())**2

    def local_measure(self, config):
        '''
        get local quantities energy_loc, grad_loc.

        Args:
            config (1darray): the bit string as a configuration.

        Returns:
            number, list: local energy and local gradients for variables.
        '''
        psi_loc = self.ansatz.psi(self.data, torch.from_numpy(config))

        # get gradients {d/dW}_{loc}
        self.ansatz.zero_grad()
        psi_loc.backward()
        grad_loc = [p.grad.data/psi_loc.item() for p in self.ansatz.parameters()]
#         grad_loc = [p.grad.data for p in self.ansatz.parameters()]

        # E_{loc}
        edge_index = sort_edge_index(self.data.edge_index)[0]
        idx_list = []
        for i in range(self.data.edge_index.shape[1]):
            if self.data.edge_index[0,i] < self.data.edge_index[1,i]:
                idx_list.append(self.data.edge_index[:,i].numpy().tolist())
        eloc = self.energy_loc(config, lambda x: self.ansatz.psi(self.data, torch.from_numpy(x)).data, psi_loc.data, idx_list)
        return eloc.item(), grad_loc

    @staticmethod
    def propose_config(old_config):
        '''
        flip two positions as suggested spin flips.

        Args:
            old_config (1darray): spin configuration, which is a [-1,1] string.

        Returns:
            1darray: new spin configuration.
        '''

        num_spin = len(old_config)
        upmask = old_config == 1
        flips = np.random.randint(0, num_spin // 2, 2)
        iflip0 = np.where(upmask)[0][flips[0]]
        iflip1 = np.where(~upmask)[0][flips[1]]

        config = old_config.copy()
        config[iflip0] = -1
        config[iflip1] = 1
        
        
        # randomly flip one of the spins
#         def flip(config, idx):
#             new_config = config.copy()
#             new_config[idx] = -new_config[idx]
#             return new_config
        
#         idx = np.random.randint(0, len(old_config), 1)
#         config = flip(old_config, idx)
        
        
        return config

def flip(s, idx):
    sflip = deepcopy(s)
    sflip[idx] = -sflip[idx]
    return sflip

def heisenberg_loc(config, psi_func, psi_loc, idx_list, h=-0.5, J=-1):
    
    
    # sigma_z * sigma_z
    e_part1 = 0
    for idx in idx_list:
        if config[idx[0]] == config[idx[1]]:
            e_part1 += 1
        else:
            e_part1 -= 1

  
    # sigma_x * sigma_x
    e_part2 = 0
    for idx in idx_list:
        config_i = flip(config, idx[0])
        config_i = flip(config_i, idx[1])
        e_part2 += (psi_func(config_i) / psi_loc)
        
        
    # sigma_y * sigma_y
    e_part3 = 0
    for idx in idx_list:
        config_i = flip(config, idx[0])
        config_i = flip(config_i, idx[1])
        if config[idx[0]] == config[idx[1]]:
            e_part3 -= (psi_func(config_i) / psi_loc)
        else:
            e_part3 += (psi_func(config_i) / psi_loc)

    return e_part1 + e_part2 + e_part3


# def get_wave_function(model, config_list):
#     psi_vec = []
#     for config in config_list:
#         config = np.array(config)
#         psi = model.ansatz.psi(torch.from_numpy(config)).detach().numpy()
#         psi_vec.append(psi)
#     return np.array(psi_vec)
# l = []
# config_list = []
# def gen(l, num_spin, config_list):
#     if num_spin == 0:
#         config_list.append(l)
#         return
#     gen(l + [1], num_spin-1, config_list)
#     gen(l + [-1], num_spin-1, config_list)
# gen(l, num_spin, config_list) 


def train(model, num_spin):
    '''
    train a model.

    Args:
        model (obj): a model that meet VMC model definition.

    '''

    initial_config = np.array([-1, 1] * (model.ansatz.num_visible // 2))

    step = 0
    lr = 0.001
    
    while True:
        # get expectation values for energy, gradient and their product,
        # as well as the precision of energy.        
        sample_list = vmc_sample(model, initial_config, num_bath=1000*num_spin, num_sample=1000*num_spin)
        energy, grad, energy_grad, precision = vmc_measure(model.local_measure, sample_list, num_spin)


        g_list = [eg - energy * g for eg, g in zip(energy_grad, grad)]
        
        # update parameter using SGD
#         for var, g in zip(model.ansatz.parameters(), g_list):
#             delta = lr * g
#             var.data -= delta
            
        # update parameter using adam
        t = 1
        eps = 1e-8
        beta1=0.9
        beta2=0.999
        sqrs = []
        vs = []
        for param in model.ansatz.parameters():
            sqrs.append(torch.zeros_like(param.data))
            vs.append(torch.zeros_like(param.data))
        
        print('learning rate: ', lr)
        for param, g, v, sqr in zip(model.ansatz.parameters(), g_list, vs, sqrs):
            v[:] = beta1 * v + (1 - beta1) * g
            sqr[:] = beta2 * sqr + (1 - beta2) * g ** 2
            v_hat = v / (1 - beta1 ** t)
            s_hat = sqr / (1 - beta2 ** t)
            param.data = param.data - lr * v_hat / torch.sqrt(s_hat + eps)
            
        
        step += 1
        if step % 20 == 0:
            if lr > 0.0001:
                print('lr decay!!!')
                lr *= 0.5
            else:
                lr = 0.0001

        
        yield energy, precision
        
        
def main():

    parser = argparse.ArgumentParser(description='quantum many body problem with variational monte carlo method')
    parser.add_argument('--device', type=int, default=0,
                        help='which gpu to use if any (default: 0)')
    parser.add_argument('--model', type=str, default='cnn',
                        help='RBM, gine-res-virtual, cnn1d, cnn2d, or gnn-transformer (default: gine-res-virtual)')
    parser.add_argument('--graph_pooling', type=str, default='sum',
                        help='graph pooling strategy mean or sum or attention (default: sum)')
    parser.add_argument('--drop_ratio', type=float, default=0,
                        help='dropout ratio (default: 0)')
    parser.add_argument('--num_layers', type=int, default=3,
                        help='number of GNN message passing layers (default: 5)')
    parser.add_argument('--emb_dim', type=int, default=32,
                        help='dimensionality of hidden units in GNNs (default: 32)')
#     parser.add_argument('--batch_size', type=int, default=256,
#                         help='input batch size for training (default: 256)')
    parser.add_argument('--epochs', type=int, default=200,
                        help='number of epochs to train (default: 200)')
    parser.add_argument('--num_workers', type=int, default=0,
                        help='number of workers (default: 0)')
    parser.add_argument('--log_dir', type=str, default="../log/gnn-transformer",
                        help='tensorboard log directory')
    parser.add_argument('--data_dir', type=str, default = './data/10_node.pt', help='directory to load graph data')
    parser.add_argument('--checkpoint_dir', type=str, default = '', help='directory to save checkpoint')
    parser.add_argument('--save_dir', type=str, default = '', help='directory to save model parameter and energy list')
    args = parser.parse_args()

    print(args)

    np.random.seed(42)
    torch.manual_seed(42)
    torch.cuda.manual_seed(42)
    random.seed(42)
    
    ### load data and get undirected unique edge index list
    global data 
    data = torch.load(args.data_dir)

    
    ### get hamiltonian matrix and ground truth energy
    if num_spin < 16:
        H = tensor_prod_graph_Heisenberg(data[0], n=10)
        e_vals, e_vecs = np.linalg.eigh(H)
        E_exact = e_vals[0]
        print('Exact energy: {}'.format(E_exact))

if __name__ == "__main__":
    main()
